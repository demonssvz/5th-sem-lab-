{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077deaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.read_csv(\"prg3.csv\")\n",
    "X = df['summary']\n",
    "y = df['overall'].apply(lambda x: 1 if x >= 4 else (0 if x <= 2 else 2))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "preprocess = lambda text: ' '.join([word.lower() for word in word_tokenize(text) if word.isalpha() and word.lower() not in stop_words])\n",
    "X_train = X_train.apply(preprocess)\n",
    "X_test = X_test.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66b3452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A195EZSQDW3E21</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Rick Bennette \"Rick Bennette\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It Does The Job Well</td>\n",
       "      <td>1377648000</td>\n",
       "      <td>08 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2C00NNG1ZQQG2</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>RustyBill \"Sunday Rocker\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n",
       "      <td>1392336000</td>\n",
       "      <td>02 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A94QU4C90B1AX</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>SEAN MASLANKA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No more pops when I record my vocals.</td>\n",
       "      <td>1392940800</td>\n",
       "      <td>02 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "2  A195EZSQDW3E21  1384719342   \n",
       "3  A2C00NNG1ZQQG2  1384719342   \n",
       "4   A94QU4C90B1AX  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "2                     Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                         RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                     SEAN MASLANKA    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Not much to write about here, but it does exac...      5.0   \n",
       "1  The product does exactly as it should and is q...      5.0   \n",
       "2  The primary job of this device is to block the...      5.0   \n",
       "3  Nice windscreen protects my MXL mic and preven...      5.0   \n",
       "4  This pop filter is great. It looks and perform...      5.0   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \n",
       "0                                   good      1393545600  02 28, 2014  \n",
       "1                                   Jake      1363392000  03 16, 2013  \n",
       "2                   It Does The Job Well      1377648000  08 28, 2013  \n",
       "3          GOOD WINDSCREEN FOR THE MONEY      1392336000  02 14, 2014  \n",
       "4  No more pops when I record my vocals.      1392940800  02 21, 2014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50304a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf(term, document):\n",
    "    words = document.split()\n",
    "    return words.count(term) / (len(words) + 1)\n",
    "\n",
    "def calculate_idf(term, documents):\n",
    "    document_containing_term = sum(1 for document in documents if term in document.split())\n",
    "    return math.log(len(documents) / (document_containing_term + 1)) if document_containing_term > 0 else 0\n",
    "\n",
    "all_documents = X_train.tolist() + X_test.tolist()\n",
    "idf_values = {term: calculate_idf(term, all_documents) for term in set(' '.join(all_documents).split())}\n",
    "\n",
    "vocabulary = sorted(list(idf_values.keys()))\n",
    "\n",
    "X_train_tfidf_manual = []\n",
    "for document in X_train:\n",
    "    tfidf_vector = [calculate_tf(term, document) * idf_values[term] for term in vocabulary]\n",
    "    X_train_tfidf_manual.append(tfidf_vector)\n",
    "\n",
    "X_test_tfidf_manual = []\n",
    "for document in X_test:\n",
    "    tfidf_vector = [calculate_tf(term, document) * idf_values[term] for term in vocabulary]\n",
    "    X_test_tfidf_manual.append(tfidf_vector)\n",
    "\n",
    "X_train_tfidf_manual = np.array(X_train_tfidf_manual)\n",
    "X_test_tfidf_manual = np.array(X_test_tfidf_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c0ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8840532640467684\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000).fit(X_train_tfidf_manual, y_train)\n",
    "y_pred = model.predict(X_test_tfidf_manual)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1124116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "new_text = \"It's good\"\n",
    "\n",
    "new_text_tfidf_manual = [calculate_tf(term, preprocess(new_text)) * idf_values[term] for term in vocabulary]\n",
    "predicted_sentiment = model.predict([new_text_tfidf_manual])\n",
    "\n",
    "sentiment_mapping = {0: \"Negative\", 1: \"Positive\", 2: \"Neutral\"}\n",
    "predicted_sentiment_label = sentiment_mapping.get(predicted_sentiment[0], \"Unknown\")\n",
    "\n",
    "print(\"Predicted Sentiment:\", predicted_sentiment_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f42427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "new_text = \"It's okay\"\n",
    "\n",
    "new_text_tfidf_manual = [calculate_tf(term, preprocess(new_text)) * idf_values[term] for term in vocabulary]\n",
    "predicted_sentiment = model.predict([new_text_tfidf_manual])\n",
    "\n",
    "sentiment_mapping = {0: \"Negative\", 1: \"Positive\", 2: \"Neutral\"}\n",
    "predicted_sentiment_label = sentiment_mapping.get(predicted_sentiment[0], \"Unknown\")\n",
    "\n",
    "print(\"Predicted Sentiment:\", predicted_sentiment_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91cc7b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Predict on new text\n",
    "    new_text = \"It's worst\"\n",
    "    new_text_tfidf_manual = [calculate_tf(term, preprocess(new_text)) * idf_values[term] for term in vocabulary]\n",
    "    predicted_sentiment = model.predict([new_text_tfidf_manual])\n",
    "    print(\"Predicted Sentiment:\", \"Positive\" if predicted_sentiment[0] == 1 else \"Negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
