{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdda3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.matutils import corpus2csc\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa163ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404284</th>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>What is one coin?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404289 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Question\n",
       "0       What is the step by step guide to invest in sh...\n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2       How can I increase the speed of my internet co...\n",
       "3       Why am I mentally very lonely? How can I solve...\n",
       "4       Which one dissolve in water quikly sugar, salt...\n",
       "...                                                   ...\n",
       "404284  How many keywords are there in the Racket prog...\n",
       "404285          Do you believe there is life after death?\n",
       "404286                                  What is one coin?\n",
       "404287  What is the approx annual cost of living while...\n",
       "404288              What is like to have sex with cousin?\n",
       "\n",
       "[404289 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"quora_questions (1).csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4024fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.sample(n=10000, axis=0)\n",
    "\n",
    "data= data['Question']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1e58e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284749                           Do you still love your ex?\n",
       "173007    How much is one million and one billion in lak...\n",
       "397585                                   What Is Etymology?\n",
       "296822           How is the Ferrari 488 compare to the 458?\n",
       "124253    Chamath Palihapitiya: How do you manage ego an...\n",
       "Name: Question, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b8eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RVCCF011\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\RVCCF011\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RVCCF011\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "284749                                  [still, love, ex, ]\n",
       "173007    [much, one, million, one, billion, lakh, crore, ]\n",
       "397585                                        [etymology, ]\n",
       "296822                       [ferrari, 488, compare, 458, ]\n",
       "124253    [chamath, palihapitiya, , manage, ego, humilit...\n",
       "                                ...                        \n",
       "219315                      [fast, lose, weight, 3, week, ]\n",
       "361522    [follow, someone, instagram, see, many, time, ...\n",
       "120250                           [fact, social, tradebiz, ]\n",
       "232514                          [best, book, learn, java, ]\n",
       "243664                                  [memorize, lyric, ]\n",
       "Name: Question, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "#function to lemmatize and remove stopwords from the text data\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    import re\n",
    "    special_chars = r'[,.:;?\\(\\'\"\\s]'\n",
    "    words = [re.sub(special_chars, '', word) for word in words]\n",
    "    return words\n",
    "\n",
    "\n",
    "#applying the function to the dataset\n",
    "data = data.apply(preprocess)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0cedd243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)],\n",
       " [(6, 1)],\n",
       " [(7, 1)],\n",
       " [(8, 1)],\n",
       " [(7, 1), (9, 1)],\n",
       " [(10, 1)],\n",
       " [],\n",
       " [(11, 1), (12, 1)],\n",
       " [(13, 1), (14, 1)],\n",
       " [(15, 1)],\n",
       " [(16, 1), (17, 1), (18, 1)],\n",
       " [(19, 1), (20, 1), (21, 1)],\n",
       " [(22, 1), (23, 1), (24, 1), (25, 1), (26, 1)],\n",
       " [],\n",
       " [(9, 1), (27, 1), (28, 1)],\n",
       " [(29, 1), (30, 1), (31, 1)],\n",
       " [],\n",
       " [(32, 1)],\n",
       " [(33, 1), (34, 1), (35, 1)],\n",
       " [(17, 1), (36, 1), (37, 1)],\n",
       " [(1, 1), (38, 1), (39, 1)],\n",
       " [],\n",
       " [(40, 1), (41, 1)],\n",
       " [(3, 1), (4, 1), (7, 1)],\n",
       " [(42, 1)],\n",
       " []]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb5be2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "Words: ['difference', ')', 'quora', '``', 'question', 'someone', 'money', 'online', 'number', 'used']\n",
      "Topic: 1\n",
      "Words: ['best', 'way', 'good', 'one', 'learn', 'book', 'much', 'become', 'm', 'english']\n",
      "Topic: 2\n",
      "Words: ['life', 'indian', 'note', 'india', 'country', '500', 'system', '1000', 'rupee', 'different']\n",
      "Topic: 3\n",
      "Words: ['people', 'like', 'nt', 'time', 'would', 'thing', 'ever', 'make', 'world', 'many']\n",
      "Topic: 4\n",
      "Words: ['get', 's', 'india', 'year', 'job', 'mean', 'trump', 'new', 'first', 'u']\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(data)\n",
    "\n",
    "# Filter out words that appear in fewer than 5 documents or more than 50% of the documents\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in data]\n",
    "\n",
    "# Train the LDA model\n",
    "num_topics = 5\n",
    "ldamodel = LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=20, alpha='auto', eta='auto')\n",
    "\n",
    "# Get the topics\n",
    "topics = ldamodel.show_topics(num_topics=num_topics, num_words=10, log=False, formatted=False)\n",
    "\n",
    "# Print the topics\n",
    "for topic_id, topic in topics:\n",
    "    print(\"Topic: {}\".format(topic_id))\n",
    "    print(\"Words: {}\".format([word for word, _ in topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f9a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
